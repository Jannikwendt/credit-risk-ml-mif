{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Map / Rubric Map\n",
    "\n",
    "- EDA (4 variables + business interpretation) → `# EDA (Core)` and `## EDA (Extension)`\n",
    "- Feature Engineering (≥4 features + economic rationale) → `## Feature Engineering (Economic Intuition)`\n",
    "- Train/Validation/Test usage (no leakage) → `## Train/Validation/Test Strategy (No Leakage)`\n",
    "- Models 0–3 + feature importance → `## Models (0–3)` and sub‑sections for each model\n",
    "- Model comparison → `## Model Comparison`\n",
    "- Threshold optimization (business) → `## Threshold Optimization (Business)`\n",
    "- Final test evaluation → `## Final Test Evaluation`\n",
    "- Conclusion → `## Conclusion`\n",
    "\n",
    "How to run: Restart Kernel & Run All.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric Compliance Map\n",
    "\n",
    "- EDA (4 variables + interpretation) → `## EDA (Core)` and `## EDA (Extension)`\n",
    "- Feature Engineering (≥4 features + rationale) → `## Feature Engineering (Economic Intuition)`\n",
    "- Train/Validation/Test protocol → `## Train/Validation/Test Strategy (No Leakage)`\n",
    "- Models & tuning → `## Models (0–3)` and model subsections\n",
    "- Model comparison → `## Model Comparison` + `outputs/model_comparison_validation.csv`\n",
    "- Threshold optimization → `## Threshold Optimization (Business)` + `outputs/threshold_sweep_validation.csv`\n",
    "- Business decisioning artifacts → `outputs/ev_curve_validation.png`, `outputs/approval_rate_curve_validation.png`\n",
    "- Confusion matrices → `outputs/confusion_matrix_validation_050.csv`, `outputs/confusion_matrix_validation_optimal.csv`\n",
    "- Model card → `outputs/model_card.md`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective & Dataset\n",
    "\n",
    "This notebook builds a supervised credit risk model to estimate default probability from historical loan data, following the course workflow and rubric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:30.521418Z",
     "iopub.status.busy": "2026-01-20T13:46:30.521418Z",
     "iopub.status.idle": "2026-01-20T13:46:30.526035Z",
     "shell.execute_reply": "2026-01-20T13:46:30.526035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TARGET_COL = \"default\"\n",
    "ID_COL = \"id\"\n",
    "TRAIN_PATH = \"../data/lending_club_train.csv\"\n",
    "TEST_PATH = \"../data/lending_club_test.csv\"\n",
    "\n",
    "REPO_ROOT = Path.cwd() if (Path.cwd() / \"data\").exists() else Path.cwd().parent\n",
    "OUTPUT_DIR = REPO_ROOT / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "assert (REPO_ROOT / \"data\" / \"lending_club_train.csv\").exists()\n",
    "\n",
    "PAYOFF = {\n",
    "    \"approve_nondefault\": 1,\n",
    "    \"approve_default\": -5,\n",
    "    \"reject_default\": 0,\n",
    "    \"reject_nondefault\": -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:30.529045Z",
     "iopub.status.busy": "2026-01-20T13:46:30.529045Z",
     "iopub.status.idle": "2026-01-20T13:46:32.040206Z",
     "shell.execute_reply": "2026-01-20T13:46:32.039144Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"FigureCanvasAgg is non-interactive.*\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, confusion_matrix\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.043911Z",
     "iopub.status.busy": "2026-01-20T13:46:32.042854Z",
     "iopub.status.idle": "2026-01-20T13:46:32.074859Z",
     "shell.execute_reply": "2026-01-20T13:46:32.074859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10129, 21), (2533, 21))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "df_train.shape, df_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality & Target Balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.102474Z",
     "iopub.status.busy": "2026-01-20T13:46:32.102474Z",
     "iopub.status.idle": "2026-01-20T13:46:32.109280Z",
     "shell.execute_reply": "2026-01-20T13:46:32.109280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "0    0.807187\n",
       "1    0.192813\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert TARGET_COL in df_train.columns\n",
    "assert set(np.unique(df_train[TARGET_COL])).issubset({0, 1})\n",
    "\n",
    "df_train[TARGET_COL].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Types\n",
    "\n",
    "| Variable name | Variable type | Why it matters for credit risk |\n",
    "| --- | --- | --- |\n",
    "| int_rate | numerical (continuous) | Higher rates often reflect higher borrower risk and expected loss. |\n",
    "| dti | numerical (continuous) | Higher debt-to-income suggests tighter cash flow and default risk. |\n",
    "| loan_amnt | numerical (continuous) | Larger loans increase exposure and repayment burden. |\n",
    "| grade | categorical (ordinal) | Encodes lender risk grading tied to expected default levels. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (Core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.111300Z",
     "iopub.status.busy": "2026-01-20T13:46:32.111300Z",
     "iopub.status.idle": "2026-01-20T13:46:32.250033Z",
     "shell.execute_reply": "2026-01-20T13:46:32.250033Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df_train[\"int_rate\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Interest Rates\")\n",
    "plt.xlabel(\"Interest Rate\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.254137Z",
     "iopub.status.busy": "2026-01-20T13:46:32.254137Z",
     "iopub.status.idle": "2026-01-20T13:46:32.290931Z",
     "shell.execute_reply": "2026-01-20T13:46:32.290931Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=\"default\", y=\"int_rate\", data=df_train)\n",
    "plt.title(\"Interest Rate vs Default\")\n",
    "plt.xlabel(\"Default (0 = Repaid, 1 = Default)\")\n",
    "plt.ylabel(\"Interest Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interest Rate (`int_rate`)**\n",
    "\n",
    "The interest rate reflects the lender’s assessment of borrower risk at origination.\n",
    "The distribution shows a wide range of rates, with higher interest rates being more frequent among loans that eventually defaulted.\n",
    "This suggests that interest rates already embed risk information and are strongly associated with default probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.293455Z",
     "iopub.status.busy": "2026-01-20T13:46:32.293455Z",
     "iopub.status.idle": "2026-01-20T13:46:32.411196Z",
     "shell.execute_reply": "2026-01-20T13:46:32.411196Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df_train[\"dti\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Debt-to-Income Ratio (DTI)\")\n",
    "plt.xlabel(\"DTI\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.413205Z",
     "iopub.status.busy": "2026-01-20T13:46:32.413205Z",
     "iopub.status.idle": "2026-01-20T13:46:32.446268Z",
     "shell.execute_reply": "2026-01-20T13:46:32.445676Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=\"default\", y=\"dti\", data=df_train)\n",
    "plt.title(\"DTI vs Default\")\n",
    "plt.xlabel(\"Default (0 = Repaid, 1 = Default)\")\n",
    "plt.ylabel(\"Debt-to-Income Ratio\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debt-to-Income Ratio (`dti`)**\n",
    "\n",
    "The debt-to-income ratio measures the proportion of a borrower’s income already committed to debt obligations.\n",
    "Higher DTI values indicate greater financial strain and reduced repayment capacity.\n",
    "The analysis shows that defaulted loans tend to have higher DTI levels, confirming DTI as a key risk driver in credit decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.448297Z",
     "iopub.status.busy": "2026-01-20T13:46:32.448297Z",
     "iopub.status.idle": "2026-01-20T13:46:32.612968Z",
     "shell.execute_reply": "2026-01-20T13:46:32.612968Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df_train[\"loan_amnt\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Loan Amount\")\n",
    "plt.xlabel(\"Loan Amount\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.615759Z",
     "iopub.status.busy": "2026-01-20T13:46:32.615169Z",
     "iopub.status.idle": "2026-01-20T13:46:32.652268Z",
     "shell.execute_reply": "2026-01-20T13:46:32.651403Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=\"default\", y=\"loan_amnt\", data=df_train)\n",
    "plt.title(\"Loan Amount vs Default\")\n",
    "plt.xlabel(\"Default (0 = Repaid, 1 = Default)\")\n",
    "plt.ylabel(\"Loan Amount\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loan Amount (`loan_amnt`)**\n",
    "\n",
    "The loan amount represents the size of the lender’s exposure rather than the borrower’s intrinsic credit quality.\n",
    "The distribution shows a concentration around mid-sized loans.\n",
    "The relationship with default appears weaker than for interest rate or DTI, suggesting that loan size alone is not a primary driver of default, but may interact with income or other risk factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.654658Z",
     "iopub.status.busy": "2026-01-20T13:46:32.654658Z",
     "iopub.status.idle": "2026-01-20T13:46:32.690153Z",
     "shell.execute_reply": "2026-01-20T13:46:32.689825Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"grade\", data=df_train, order=sorted(df_train[\"grade\"].unique()))\n",
    "plt.title(\"Distribution of Credit Grades\")\n",
    "plt.xlabel(\"Credit Grade\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.692111Z",
     "iopub.status.busy": "2026-01-20T13:46:32.692111Z",
     "iopub.status.idle": "2026-01-20T13:46:32.724860Z",
     "shell.execute_reply": "2026-01-20T13:46:32.724312Z"
    }
   },
   "outputs": [],
   "source": [
    "grade_default_rate = (\n",
    "    df_train\n",
    "    .groupby(\"grade\")[\"default\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=\"grade\", y=\"default\", data=grade_default_rate,\n",
    "            order=sorted(grade_default_rate[\"grade\"]))\n",
    "plt.title(\"Average Default Rate by Credit Grade\")\n",
    "plt.xlabel(\"Credit Grade\")\n",
    "plt.ylabel(\"Default Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit Grade (`grade`)**\n",
    "\n",
    "The credit grade is an ordinal categorical variable summarizing the lender’s internal credit assessment at origination.\n",
    "Lower grades are associated with significantly higher default rates, while higher grades exhibit substantially lower default frequencies.\n",
    "This clear monotonic relationship confirms that `grade` is one of the strongest predictors of default and validates its economic relevance in credit risk modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (Extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.728075Z",
     "iopub.status.busy": "2026-01-20T13:46:32.728075Z",
     "iopub.status.idle": "2026-01-20T13:46:32.733522Z",
     "shell.execute_reply": "2026-01-20T13:46:32.733522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'loan_amnt',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'annual_inc',\n",
       " 'emp_length',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'inq_last_6mths',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select numerical columns only\n",
    "num_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Exclude target itself\n",
    "num_cols = [c for c in num_cols if c != \"default\"]\n",
    "\n",
    "num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.735619Z",
     "iopub.status.busy": "2026-01-20T13:46:32.735619Z",
     "iopub.status.idle": "2026-01-20T13:46:32.749551Z",
     "shell.execute_reply": "2026-01-20T13:46:32.749050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation with Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.251016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.169246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0.102043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>0.073969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>0.072172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.068005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0.054795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.042234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>0.037639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>0.017844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc</th>\n",
       "      <td>0.014867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length</th>\n",
       "      <td>0.005045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>-0.019908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>-0.027689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>-0.046853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Correlation with Default\n",
       "int_rate                        0.251016\n",
       "term                            0.169246\n",
       "dti                             0.102043\n",
       "inq_last_6mths                  0.073969\n",
       "revol_util                      0.072172\n",
       "loan_amnt                       0.068005\n",
       "installment                     0.054795\n",
       "id                              0.042234\n",
       "pub_rec                         0.037639\n",
       "delinq_2yrs                     0.017844\n",
       "open_acc                        0.014867\n",
       "emp_length                      0.005045\n",
       "revol_bal                      -0.019908\n",
       "total_acc                      -0.027689\n",
       "annual_inc                     -0.046853"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_with_target = (\n",
    "    df_train[num_cols + [\"default\"]]\n",
    "    .corr()[\"default\"]\n",
    "    .drop(\"default\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "corr_with_target.to_frame(name=\"Correlation with Default\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (Economic Intuition)\n",
    "\n",
    "### Feature Engineering Strategy\n",
    "\n",
    "Feature engineering was guided by economic intuition rather than brute-force expansion. Engineered variables capture distinct borrower-risk dimensions: affordability/burden, leverage/utilization, credit experience/stability, and nonlinear effects, while maintaining interpretability and model stability.\n",
    "\n",
    "| Feature | Intuition |\n",
    "| --- | --- |\n",
    "| installment_to_income | installment / annual_inc |\n",
    "| loan_to_income | loan_amnt / annual_inc |\n",
    "| revol_balance_util | revol_bal * revol_util |\n",
    "| revol_balance_to_income | revol_bal / annual_inc |\n",
    "| open_to_total_acc | open_acc / total_acc |\n",
    "| recent_inquiry_flag | (inq_last_6mths > 0) |\n",
    "| log_annual_inc | log(annual_inc) |\n",
    "| sqrt_dti | sqrt(dti) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.751685Z",
     "iopub.status.busy": "2026-01-20T13:46:32.751685Z",
     "iopub.status.idle": "2026-01-20T13:46:32.756403Z",
     "shell.execute_reply": "2026-01-20T13:46:32.756403Z"
    }
   },
   "outputs": [],
   "source": [
    "ID_COL = \"id\" if \"id\" in df_train.columns else None\n",
    "\n",
    "y = df_train[TARGET_COL].astype(int)\n",
    "X = df_train.drop(columns=[TARGET_COL] + ([ID_COL] if ID_COL else []))\n",
    "\n",
    "if ID_COL is not None:\n",
    "    assert ID_COL not in X.columns\n",
    "\n",
    "X_test_final = df_test.drop(columns=([ID_COL] if ID_COL and ID_COL in df_test.columns else []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.761496Z",
     "iopub.status.busy": "2026-01-20T13:46:32.761496Z",
     "iopub.status.idle": "2026-01-20T13:46:32.777231Z",
     "shell.execute_reply": "2026-01-20T13:46:32.777231Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    annual_inc_safe = df[\"annual_inc\"].clip(lower=1)\n",
    "    total_acc_safe = df[\"total_acc\"].replace(0, np.nan)\n",
    "\n",
    "    df[\"installment_to_income\"] = df[\"installment\"] / annual_inc_safe\n",
    "    df[\"loan_to_income\"] = df[\"loan_amnt\"] / annual_inc_safe\n",
    "    df[\"revol_balance_util\"] = df[\"revol_bal\"] * df[\"revol_util\"]\n",
    "    df[\"revol_balance_to_income\"] = df[\"revol_bal\"] / annual_inc_safe\n",
    "    df[\"open_to_total_acc\"] = df[\"open_acc\"] / total_acc_safe\n",
    "    df[\"recent_inquiry_flag\"] = (df[\"inq_last_6mths\"] > 0).astype(int)\n",
    "    df[\"log_annual_inc\"] = np.log(annual_inc_safe)\n",
    "    df[\"sqrt_dti\"] = np.sqrt(df[\"dti\"].clip(lower=0))\n",
    "\n",
    "    return df\n",
    "\n",
    "engineered_cols = [\n",
    "    \"installment_to_income\",\n",
    "    \"loan_to_income\",\n",
    "    \"revol_balance_util\",\n",
    "    \"revol_balance_to_income\",\n",
    "    \"open_to_total_acc\",\n",
    "    \"recent_inquiry_flag\",\n",
    "    \"log_annual_inc\",\n",
    "    \"sqrt_dti\",\n",
    "]\n",
    "\n",
    "X_fe = add_engineered_features(X)\n",
    "X_test_fe = add_engineered_features(X_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.784257Z",
     "iopub.status.busy": "2026-01-20T13:46:32.782250Z",
     "iopub.status.idle": "2026-01-20T13:46:32.808574Z",
     "shell.execute_reply": "2026-01-20T13:46:32.808574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered columns: ['installment_to_income', 'loan_to_income', 'revol_balance_util', 'revol_balance_to_income', 'open_to_total_acc', 'recent_inquiry_flag', 'log_annual_inc', 'sqrt_dti']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "installment_to_income      0.0\n",
       "loan_to_income             0.0\n",
       "revol_balance_util         0.0\n",
       "revol_balance_to_income    0.0\n",
       "open_to_total_acc          0.0\n",
       "recent_inquiry_flag        0.0\n",
       "log_annual_inc             0.0\n",
       "sqrt_dti                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Engineered columns:\", engineered_cols)\n",
    "\n",
    "X_fe[engineered_cols].describe().T[[\"mean\", \"std\", \"min\", \"max\"]]\n",
    "\n",
    "X_fe[engineered_cols].isna().mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.812983Z",
     "iopub.status.busy": "2026-01-20T13:46:32.812983Z",
     "iopub.status.idle": "2026-01-20T13:46:32.901623Z",
     "shell.execute_reply": "2026-01-20T13:46:32.900548Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    df_train[num_cols + [\"default\"]].corr(),\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title(\"Correlation Matrix (Numerical Variables)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation with Default (Numerical Variables)**\n",
    "\n",
    "As an extension of the initial EDA, we examine linear correlations between numerical variables and the default indicator.\n",
    "Variables such as interest rate and debt-to-income ratio show stronger positive correlations with default, while income-related variables tend to be negatively correlated.\n",
    "These results are consistent with economic intuition and support the relevance of these variables for credit risk modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.903643Z",
     "iopub.status.busy": "2026-01-20T13:46:32.903643Z",
     "iopub.status.idle": "2026-01-20T13:46:32.909229Z",
     "shell.execute_reply": "2026-01-20T13:46:32.909229Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[\"dti_quartile\"] = pd.qcut(df_train[\"dti\"], q=4, labels=[\"Q1 (Low)\", \"Q2\", \"Q3\", \"Q4 (High)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.911329Z",
     "iopub.status.busy": "2026-01-20T13:46:32.910291Z",
     "iopub.status.idle": "2026-01-20T13:46:32.917691Z",
     "shell.execute_reply": "2026-01-20T13:46:32.917691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dti_quartile</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1 (Low)</td>\n",
       "      <td>0.151599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.161672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.212732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4 (High)</td>\n",
       "      <td>0.245358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dti_quartile   default\n",
       "0     Q1 (Low)  0.151599\n",
       "1           Q2  0.161672\n",
       "2           Q3  0.212732\n",
       "3    Q4 (High)  0.245358"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dti_default_by_quantile = (\n",
    "    df_train\n",
    "    .groupby(\"dti_quartile\", observed=False)[\"default\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "dti_default_by_quantile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.919993Z",
     "iopub.status.busy": "2026-01-20T13:46:32.919993Z",
     "iopub.status.idle": "2026-01-20T13:46:32.946503Z",
     "shell.execute_reply": "2026-01-20T13:46:32.946503Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    x=\"dti_quartile\",\n",
    "    y=\"default\",\n",
    "    data=dti_default_by_quantile\n",
    ")\n",
    "plt.title(\"Default Rate by DTI Quartile\")\n",
    "plt.xlabel(\"DTI Quartile\")\n",
    "plt.ylabel(\"Average Default Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default Rate by DTI Quantiles**\n",
    "\n",
    "To capture potential nonlinear effects, we analyze default rates across quartiles of the debt-to-income ratio.\n",
    "Default probability increases monotonically from the lowest to the highest DTI quartile, indicating that borrower risk rises disproportionately at higher levels of indebtedness.\n",
    "This supports the inclusion of nonlinear transformations or interaction-based features in subsequent modeling steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.947676Z",
     "iopub.status.busy": "2026-01-20T13:46:32.947676Z",
     "iopub.status.idle": "2026-01-20T13:46:32.952606Z",
     "shell.execute_reply": "2026-01-20T13:46:32.952606Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.drop(columns=[\"dti_quartile\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.955228Z",
     "iopub.status.busy": "2026-01-20T13:46:32.955228Z",
     "iopub.status.idle": "2026-01-20T13:46:32.967234Z",
     "shell.execute_reply": "2026-01-20T13:46:32.966530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79044496</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.99</td>\n",
       "      <td>363.97</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26376.0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43246030</td>\n",
       "      <td>15150.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>495.92</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>39.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19459.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>641694</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14.83</td>\n",
       "      <td>303.38</td>\n",
       "      <td>D</td>\n",
       "      <td>D3</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>12.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8078.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>moving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70981628</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>192.90</td>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Verified</td>\n",
       "      <td>25.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57792301</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13.33</td>\n",
       "      <td>343.84</td>\n",
       "      <td>C</td>\n",
       "      <td>C3</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15979.0</td>\n",
       "      <td>53.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  loan_amnt  term  int_rate  installment grade sub_grade  \\\n",
       "0  79044496    16000.0  60.0     12.99       363.97     C        C2   \n",
       "1  43246030    15150.0  36.0     10.99       495.92     B        B4   \n",
       "2    641694    12800.0  60.0     14.83       303.38     D        D3   \n",
       "3  70981628     6000.0  36.0      9.75       192.90     B        B3   \n",
       "4  57792301    15000.0  60.0     13.33       343.84     C        C3   \n",
       "\n",
       "   annual_inc  emp_length home_ownership verification_status    dti  \\\n",
       "0     49000.0         5.0           RENT     Source Verified  15.94   \n",
       "1     38000.0         8.0       MORTGAGE        Not Verified  39.96   \n",
       "2     75000.0         0.0           RENT     Source Verified  12.43   \n",
       "3     70000.0         0.0       MORTGAGE            Verified  25.53   \n",
       "4     96000.0         3.0           RENT     Source Verified  13.44   \n",
       "\n",
       "   delinq_2yrs  inq_last_6mths  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0          0.0             0.0       9.0      0.0    26376.0        85.4   \n",
       "1          1.0             1.0      10.0      0.0    19459.0        63.2   \n",
       "2          0.0             0.0      12.0      0.0     8078.0        35.0   \n",
       "3          1.0             1.0       9.0      0.0     2048.0        39.4   \n",
       "4          0.0             0.0      11.0      1.0    15979.0        53.3   \n",
       "\n",
       "   total_acc             purpose  default  \n",
       "0       19.0  debt_consolidation        0  \n",
       "1       38.0         credit_card        0  \n",
       "2       13.0              moving        0  \n",
       "3       16.0  debt_consolidation        0  \n",
       "4       36.0  debt_consolidation        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.969359Z",
     "iopub.status.busy": "2026-01-20T13:46:32.969359Z",
     "iopub.status.idle": "2026-01-20T13:46:32.976258Z",
     "shell.execute_reply": "2026-01-20T13:46:32.976258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10129 entries, 0 to 10128\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   10129 non-null  int64  \n",
      " 1   loan_amnt            10129 non-null  float64\n",
      " 2   term                 10129 non-null  float64\n",
      " 3   int_rate             10129 non-null  float64\n",
      " 4   installment          10129 non-null  float64\n",
      " 5   grade                10129 non-null  object \n",
      " 6   sub_grade            10129 non-null  object \n",
      " 7   annual_inc           10129 non-null  float64\n",
      " 8   emp_length           10129 non-null  float64\n",
      " 9   home_ownership       10129 non-null  object \n",
      " 10  verification_status  10129 non-null  object \n",
      " 11  dti                  10129 non-null  float64\n",
      " 12  delinq_2yrs          10129 non-null  float64\n",
      " 13  inq_last_6mths       10129 non-null  float64\n",
      " 14  open_acc             10129 non-null  float64\n",
      " 15  pub_rec              10129 non-null  float64\n",
      " 16  revol_bal            10129 non-null  float64\n",
      " 17  revol_util           10129 non-null  float64\n",
      " 18  total_acc            10129 non-null  float64\n",
      " 19  purpose              10129 non-null  object \n",
      " 20  default              10129 non-null  int64  \n",
      "dtypes: float64(14), int64(2), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.976258Z",
     "iopub.status.busy": "2026-01-20T13:46:32.976258Z",
     "iopub.status.idle": "2026-01-20T13:46:32.982796Z",
     "shell.execute_reply": "2026-01-20T13:46:32.982796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       int64\n",
       "loan_amnt              float64\n",
       "term                   float64\n",
       "int_rate               float64\n",
       "installment            float64\n",
       "grade                   object\n",
       "sub_grade               object\n",
       "annual_inc             float64\n",
       "emp_length             float64\n",
       "home_ownership          object\n",
       "verification_status     object\n",
       "dti                    float64\n",
       "delinq_2yrs            float64\n",
       "inq_last_6mths         float64\n",
       "open_acc               float64\n",
       "pub_rec                float64\n",
       "revol_bal              float64\n",
       "revol_util             float64\n",
       "total_acc              float64\n",
       "purpose                 object\n",
       "default                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation/Test Strategy (No Leakage)\n",
    "\n",
    "Training uses only `X_train`/`y_train`, validation is used for tuning, and the test set is held out for final evaluation. `X_test_final` is never used in any model `.fit()` calls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (0–3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning grids are intentionally small to ensure fast execution and reproducible results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0 — Logistic Regression (Baseline)\n",
    "\n",
    "This baseline provides a simple, interpretable benchmark for credit risk prediction. Logistic Regression serves as a linear reference point for comparison with more complex models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.984950Z",
     "iopub.status.busy": "2026-01-20T13:46:32.984950Z",
     "iopub.status.idle": "2026-01-20T13:46:32.993622Z",
     "shell.execute_reply": "2026-01-20T13:46:32.993622Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_fe,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:32.995714Z",
     "iopub.status.busy": "2026-01-20T13:46:32.995714Z",
     "iopub.status.idle": "2026-01-20T13:46:32.998950Z",
     "shell.execute_reply": "2026-01-20T13:46:32.997868Z"
    }
   },
   "outputs": [],
   "source": [
    "assert X_test_final is not X_train\n",
    "assert X_test_final is not X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:33.000388Z",
     "iopub.status.busy": "2026-01-20T13:46:33.000388Z",
     "iopub.status.idle": "2026-01-20T13:46:33.004540Z",
     "shell.execute_reply": "2026-01-20T13:46:33.004033Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:33.007186Z",
     "iopub.status.busy": "2026-01-20T13:46:33.007186Z",
     "iopub.status.idle": "2026-01-20T13:46:33.139009Z",
     "shell.execute_reply": "2026-01-20T13:46:33.139009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline fitted. Preprocess: num + cat. Model: LogisticRegression.\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "log_reg_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", log_reg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "print(\"Pipeline fitted. Preprocess: num + cat. Model: LogisticRegression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:33.141023Z",
     "iopub.status.busy": "2026-01-20T13:46:33.141023Z",
     "iopub.status.idle": "2026-01-20T13:46:33.144880Z",
     "shell.execute_reply": "2026-01-20T13:46:33.144880Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, pipeline, X_train, y_train, X_val, y_val):\n",
    "    train_probs = pipeline.predict_proba(X_train)[:, 1]\n",
    "    val_probs = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_probs))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_probs))\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_probs)\n",
    "    val_auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Train_RMSE\": train_rmse,\n",
    "        \"Val_RMSE\": val_rmse,\n",
    "        \"Train_AUC\": train_auc,\n",
    "        \"Val_AUC\": val_auc,\n",
    "        \"AUC_Gap\": train_auc - val_auc,\n",
    "        \"RMSE_Gap\": val_rmse - train_rmse,\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:33.146891Z",
     "iopub.status.busy": "2026-01-20T13:46:33.146891Z",
     "iopub.status.idle": "2026-01-20T13:46:33.178646Z",
     "shell.execute_reply": "2026-01-20T13:46:33.178359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Val_AUC</th>\n",
       "      <th>AUC_Gap</th>\n",
       "      <th>RMSE_Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.374962</td>\n",
       "      <td>0.379806</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train_RMSE  Val_RMSE  Train_AUC   Val_AUC   AUC_Gap  \\\n",
       "0  Logistic Regression    0.374962  0.379806   0.712319  0.690397  0.021921   \n",
       "\n",
       "   RMSE_Gap  \n",
       "0  0.004845  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_metrics = evaluate_model(\n",
    "    \"Logistic Regression\",\n",
    "    log_reg_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    ")\n",
    "\n",
    "results_df = pd.concat([results_df, pd.DataFrame([log_reg_metrics])], ignore_index=True)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 — Decision Tree (Tuned)\n",
    "\n",
    "Decision Trees capture nonlinearities and interactions among borrower characteristics. Because they can overfit, we tune key hyperparameters using the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:33.182305Z",
     "iopub.status.busy": "2026-01-20T13:46:33.182305Z",
     "iopub.status.idle": "2026-01-20T13:46:33.187049Z",
     "shell.execute_reply": "2026-01-20T13:46:33.187049Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_cols_tree = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_tree = [c for c in X_train.columns if c not in categorical_cols_tree]\n",
    "\n",
    "numeric_transformer_tree = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer_tree = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer_tree, num_cols_tree),\n",
    "        (\"cat\", categorical_transformer_tree, categorical_cols_tree),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:33.189053Z",
     "iopub.status.busy": "2026-01-20T13:46:33.189053Z",
     "iopub.status.idle": "2026-01-20T13:46:34.426862Z",
     "shell.execute_reply": "2026-01-20T13:46:34.426263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>chosen_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.715711</td>\n",
       "      <td>0.659281</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0.715711</td>\n",
       "      <td>0.659281</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.719240</td>\n",
       "      <td>0.656571</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.712199</td>\n",
       "      <td>0.656276</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.720761</td>\n",
       "      <td>0.654881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.736669</td>\n",
       "      <td>0.648326</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.741372</td>\n",
       "      <td>0.646720</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_leaf  train_auc   val_auc  chosen_flag\n",
       "0           3                50   0.689931  0.667967         True\n",
       "1           3               100   0.689931  0.667967        False\n",
       "2           3               200   0.689931  0.667967        False\n",
       "11         10               200   0.715711  0.659281        False\n",
       "8           7               200   0.715711  0.659281        False\n",
       "3           5                50   0.719240  0.656571        False\n",
       "5           5               200   0.712199  0.656276        False\n",
       "4           5               100   0.720761  0.654881        False\n",
       "7           7               100   0.736669  0.648326        False\n",
       "10         10               100   0.741372  0.646720        False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"min_samples_leaf\": [50, 100, 200],\n",
    "}\n",
    "\n",
    "dt_tuning_results = []\n",
    "\n",
    "for max_depth in param_grid[\"max_depth\"]:\n",
    "    for min_samples_leaf in param_grid[\"min_samples_leaf\"]:\n",
    "        tree_model = DecisionTreeClassifier(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "\n",
    "        tree_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocess_tree),\n",
    "                (\"model\", tree_model),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        tree_pipeline.fit(X_train, y_train)\n",
    "        train_probs = tree_pipeline.predict_proba(X_train)[:, 1]\n",
    "        val_probs = tree_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        dt_tuning_results.append(\n",
    "            {\n",
    "                \"max_depth\": max_depth,\n",
    "                \"min_samples_leaf\": min_samples_leaf,\n",
    "                \"train_auc\": roc_auc_score(y_train, train_probs),\n",
    "                \"val_auc\": roc_auc_score(y_val, val_probs),\n",
    "                \"chosen_flag\": False,\n",
    "            }\n",
    "        )\n",
    "\n",
    "dt_tuning_df = pd.DataFrame(dt_tuning_results)\n",
    "\n",
    "best_dt_idx = dt_tuning_df[\"val_auc\"].idxmax()\n",
    "dt_tuning_df.loc[best_dt_idx, \"chosen_flag\"] = True\n",
    "best_dt_params = dt_tuning_df.loc[best_dt_idx, [\"max_depth\", \"min_samples_leaf\"]].to_dict()\n",
    "\n",
    "# Keep compatibility with prior naming\n",
    "best_params = best_dt_params\n",
    "tuning_df = dt_tuning_df\n",
    "\n",
    "dt_tuning_df.sort_values(\"val_auc\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:34.428821Z",
     "iopub.status.busy": "2026-01-20T13:46:34.428821Z",
     "iopub.status.idle": "2026-01-20T13:46:34.491564Z",
     "shell.execute_reply": "2026-01-20T13:46:34.491564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline fitted. Preprocess: num + cat. Model: DecisionTreeClassifier.\n"
     ]
    }
   ],
   "source": [
    "best_params = tuning_df.loc[tuning_df[\"val_auc\"].idxmax()].to_dict()\n",
    "\n",
    "best_tree = DecisionTreeClassifier(\n",
    "    max_depth=int(best_params[\"max_depth\"]),\n",
    "    min_samples_leaf=int(best_params[\"min_samples_leaf\"]),\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "best_tree_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_tree),\n",
    "        (\"model\", best_tree),\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_tree_pipeline.fit(X_train, y_train)\n",
    "print(\"Pipeline fitted. Preprocess: num + cat. Model: DecisionTreeClassifier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:34.493662Z",
     "iopub.status.busy": "2026-01-20T13:46:34.493662Z",
     "iopub.status.idle": "2026-01-20T13:46:34.523461Z",
     "shell.execute_reply": "2026-01-20T13:46:34.523461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Val_AUC</th>\n",
       "      <th>AUC_Gap</th>\n",
       "      <th>RMSE_Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.374962</td>\n",
       "      <td>0.379806</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.383817</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.004133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train_RMSE  Val_RMSE  Train_AUC   Val_AUC   AUC_Gap  \\\n",
       "0  Logistic Regression    0.374962  0.379806   0.712319  0.690397  0.021921   \n",
       "1        Decision Tree    0.379684  0.383817   0.689931  0.667967  0.021965   \n",
       "\n",
       "   RMSE_Gap  \n",
       "0  0.004845  \n",
       "1  0.004133  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_metrics = evaluate_model(\n",
    "    \"Decision Tree\",\n",
    "    best_tree_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    ")\n",
    "\n",
    "results_df = pd.concat([results_df, pd.DataFrame([dt_metrics])], ignore_index=True)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:34.526187Z",
     "iopub.status.busy": "2026-01-20T13:46:34.526187Z",
     "iopub.status.idle": "2026-01-20T13:46:34.559231Z",
     "shell.execute_reply": "2026-01-20T13:46:34.559231Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = best_tree_pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "importances = best_tree_pipeline.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame(\n",
    "    {\"feature\": feature_names, \"importance\": importances}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    data=importance_df.head(10),\n",
    "    orient=\"h\",\n",
    ")\n",
    "plt.title(\"Top 10 Feature Importances (Decision Tree)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 — Random Forest (Bagging)\n",
    "\n",
    "Random Forest reduces variance via bagging and feature subsampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:46:34.563422Z",
     "iopub.status.busy": "2026-01-20T13:46:34.563422Z",
     "iopub.status.idle": "2026-01-20T13:47:19.674771Z",
     "shell.execute_reply": "2026-01-20T13:47:19.674051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline fitted. Preprocess: num + cat. Model: RandomForestClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Val_AUC</th>\n",
       "      <th>AUC_Gap</th>\n",
       "      <th>RMSE_Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.374962</td>\n",
       "      <td>0.379806</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.383817</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.004133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.351933</td>\n",
       "      <td>0.379290</td>\n",
       "      <td>0.856029</td>\n",
       "      <td>0.693914</td>\n",
       "      <td>0.162116</td>\n",
       "      <td>0.027356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train_RMSE  Val_RMSE  Train_AUC   Val_AUC   AUC_Gap  \\\n",
       "0  Logistic Regression    0.374962  0.379806   0.712319  0.690397  0.021921   \n",
       "1        Decision Tree    0.379684  0.383817   0.689931  0.667967  0.021965   \n",
       "2        Random Forest    0.351933  0.379290   0.856029  0.693914  0.162116   \n",
       "\n",
       "   RMSE_Gap  \n",
       "0  0.004845  \n",
       "1  0.004133  \n",
       "2  0.027356  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols_rf = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_rf = [c for c in X_train.columns if c not in categorical_cols_rf]\n",
    "\n",
    "numeric_transformer_rf = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer_rf = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer_rf, num_cols_rf),\n",
    "        (\"cat\", categorical_transformer_rf, categorical_cols_rf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 20, 50],\n",
    "    \"max_features\": [\"sqrt\", 0.5],\n",
    "}\n",
    "\n",
    "rf_tuning_results = []\n",
    "\n",
    "for n_estimators in rf_grid[\"n_estimators\"]:\n",
    "    for max_depth in rf_grid[\"max_depth\"]:\n",
    "        for min_samples_leaf in rf_grid[\"min_samples_leaf\"]:\n",
    "            for max_features in rf_grid[\"max_features\"]:\n",
    "                rf_model = RandomForestClassifier(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    max_features=max_features,\n",
    "                    random_state=RANDOM_STATE,\n",
    "                    n_jobs=-1,\n",
    "                )\n",
    "\n",
    "                rf_pipeline = Pipeline(\n",
    "                    steps=[\n",
    "                        (\"preprocess\", preprocess_rf),\n",
    "                        (\"model\", rf_model),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                rf_pipeline.fit(X_train, y_train)\n",
    "                val_probs = rf_pipeline.predict_proba(X_val)[:, 1]\n",
    "                val_auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "                rf_tuning_results.append(\n",
    "                    {\n",
    "                        \"n_estimators\": n_estimators,\n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"min_samples_leaf\": min_samples_leaf,\n",
    "                        \"max_features\": max_features,\n",
    "                        \"val_auc\": val_auc,\n",
    "                        \"chosen_flag\": False,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "rf_tuning_df = pd.DataFrame(rf_tuning_results)\n",
    "rf_tuning_df[\"depth_rank\"] = rf_tuning_df[\"max_depth\"].apply(lambda d: 999 if d is None else d)\n",
    "\n",
    "rf_sorted = rf_tuning_df.sort_values(\n",
    "    [\"val_auc\", \"n_estimators\", \"depth_rank\"],\n",
    "    ascending=[False, True, True],\n",
    ")\n",
    "\n",
    "best_rf_idx = rf_sorted.index[0]\n",
    "rf_tuning_df.loc[best_rf_idx, \"chosen_flag\"] = True\n",
    "best_rf_params = rf_tuning_df.loc[\n",
    "    best_rf_idx, [\"n_estimators\", \"max_depth\", \"min_samples_leaf\", \"max_features\"]\n",
    "].to_dict()\n",
    "\n",
    "if pd.isna(best_rf_params[\"max_depth\"]):\n",
    "    best_rf_params[\"max_depth\"] = None\n",
    "\n",
    "rf_tuning_df = rf_tuning_df.drop(columns=[\"depth_rank\"])\n",
    "\n",
    "rf_tuning_df.sort_values(\"val_auc\", ascending=False).head(10)\n",
    "\n",
    "rf_best_model = RandomForestClassifier(\n",
    "    n_estimators=int(best_rf_params[\"n_estimators\"]),\n",
    "    max_depth=best_rf_params[\"max_depth\"],\n",
    "    min_samples_leaf=int(best_rf_params[\"min_samples_leaf\"]),\n",
    "    max_features=best_rf_params[\"max_features\"],\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf_best_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_rf),\n",
    "        (\"model\", rf_best_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_best_pipeline.fit(X_train, y_train)\n",
    "print(\"Pipeline fitted. Preprocess: num + cat. Model: RandomForestClassifier.\")\n",
    "\n",
    "rf_metrics = evaluate_model(\n",
    "    \"Random Forest\",\n",
    "    rf_best_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    ")\n",
    "\n",
    "results_df = pd.concat([results_df, pd.DataFrame([rf_metrics])], ignore_index=True)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:47:19.676938Z",
     "iopub.status.busy": "2026-01-20T13:47:19.676938Z",
     "iopub.status.idle": "2026-01-20T13:47:19.762520Z",
     "shell.execute_reply": "2026-01-20T13:47:19.760864Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_feature_names = rf_best_pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "rf_importances = rf_best_pipeline.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "rf_importance_df = pd.DataFrame(\n",
    "    {\"feature\": rf_feature_names, \"importance\": rf_importances}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    data=rf_importance_df.head(10),\n",
    "    orient=\"h\",\n",
    ")\n",
    "plt.title(\"Top 10 Feature Importances (Random Forest)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 — Gradient Boosting (Boosting)\n",
    "\n",
    "Gradient Boosting reduces bias via sequential weak learners.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:47:19.764611Z",
     "iopub.status.busy": "2026-01-20T13:47:19.764611Z",
     "iopub.status.idle": "2026-01-20T13:49:00.019122Z",
     "shell.execute_reply": "2026-01-20T13:49:00.019122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline fitted. Preprocess: num + cat. Model: GradientBoostingClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Val_AUC</th>\n",
       "      <th>AUC_Gap</th>\n",
       "      <th>RMSE_Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.374962</td>\n",
       "      <td>0.379806</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.383817</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.004133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.351933</td>\n",
       "      <td>0.379290</td>\n",
       "      <td>0.856029</td>\n",
       "      <td>0.693914</td>\n",
       "      <td>0.162116</td>\n",
       "      <td>0.027356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.357419</td>\n",
       "      <td>0.380680</td>\n",
       "      <td>0.786562</td>\n",
       "      <td>0.693174</td>\n",
       "      <td>0.093389</td>\n",
       "      <td>0.023260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train_RMSE  Val_RMSE  Train_AUC   Val_AUC   AUC_Gap  \\\n",
       "0  Logistic Regression    0.374962  0.379806   0.712319  0.690397  0.021921   \n",
       "1        Decision Tree    0.379684  0.383817   0.689931  0.667967  0.021965   \n",
       "2        Random Forest    0.351933  0.379290   0.856029  0.693914  0.162116   \n",
       "3    Gradient Boosting    0.357419  0.380680   0.786562  0.693174  0.093389   \n",
       "\n",
       "   RMSE_Gap  \n",
       "0  0.004845  \n",
       "1  0.004133  \n",
       "2  0.027356  \n",
       "3  0.023260  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols_gb = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols_gb = [c for c in X_train.columns if c not in categorical_cols_gb]\n",
    "\n",
    "numeric_transformer_gb = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer_gb = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer_gb, num_cols_gb),\n",
    "        (\"cat\", categorical_transformer_gb, categorical_cols_gb),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gb_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_depth\": [2, 3],\n",
    "    \"subsample\": [1.0],\n",
    "}\n",
    "\n",
    "gb_tuning_results = []\n",
    "\n",
    "for n_estimators in gb_grid[\"n_estimators\"]:\n",
    "    for learning_rate in gb_grid[\"learning_rate\"]:\n",
    "        for max_depth in gb_grid[\"max_depth\"]:\n",
    "            for subsample in gb_grid[\"subsample\"]:\n",
    "                gb_model = GradientBoostingClassifier(\n",
    "                    n_estimators=n_estimators,\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_depth=max_depth,\n",
    "                    subsample=subsample,\n",
    "                    random_state=RANDOM_STATE,\n",
    "                )\n",
    "\n",
    "                gb_pipeline = Pipeline(\n",
    "                    steps=[\n",
    "                        (\"preprocess\", preprocess_gb),\n",
    "                        (\"model\", gb_model),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                gb_pipeline.fit(X_train, y_train)\n",
    "                val_probs = gb_pipeline.predict_proba(X_val)[:, 1]\n",
    "                val_auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "                gb_tuning_results.append(\n",
    "                    {\n",
    "                        \"n_estimators\": n_estimators,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"subsample\": subsample,\n",
    "                        \"val_auc\": val_auc,\n",
    "                        \"chosen_flag\": False,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "gb_tuning_df = pd.DataFrame(gb_tuning_results)\n",
    "\n",
    "gb_sorted = gb_tuning_df.sort_values(\n",
    "    [\"val_auc\", \"n_estimators\", \"max_depth\", \"learning_rate\"],\n",
    "    ascending=[False, True, True, True],\n",
    ")\n",
    "\n",
    "best_gb_idx = gb_sorted.index[0]\n",
    "gb_tuning_df.loc[best_gb_idx, \"chosen_flag\"] = True\n",
    "best_gb_params = gb_tuning_df.loc[\n",
    "    best_gb_idx, [\"n_estimators\", \"learning_rate\", \"max_depth\", \"subsample\"]\n",
    "].to_dict()\n",
    "\n",
    "gb_tuning_df.sort_values(\"val_auc\", ascending=False).head(10)\n",
    "\n",
    "gb_best_model = GradientBoostingClassifier(\n",
    "    n_estimators=int(best_gb_params[\"n_estimators\"]),\n",
    "    learning_rate=best_gb_params[\"learning_rate\"],\n",
    "    max_depth=int(best_gb_params[\"max_depth\"]),\n",
    "    subsample=best_gb_params[\"subsample\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "gb_best_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_gb),\n",
    "        (\"model\", gb_best_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gb_best_pipeline.fit(X_train, y_train)\n",
    "print(\"Pipeline fitted. Preprocess: num + cat. Model: GradientBoostingClassifier.\")\n",
    "\n",
    "gb_metrics = evaluate_model(\n",
    "    \"Gradient Boosting\",\n",
    "    gb_best_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    ")\n",
    "\n",
    "results_df = pd.concat([results_df, pd.DataFrame([gb_metrics])], ignore_index=True)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.021367Z",
     "iopub.status.busy": "2026-01-20T13:49:00.021367Z",
     "iopub.status.idle": "2026-01-20T13:49:00.058706Z",
     "shell.execute_reply": "2026-01-20T13:49:00.058706Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_feature_names = gb_best_pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "gb_importances = gb_best_pipeline.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "gb_importance_df = pd.DataFrame(\n",
    "    {\"feature\": gb_feature_names, \"importance\": gb_importances}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    data=gb_importance_df.head(10),\n",
    "    orient=\"h\",\n",
    ")\n",
    "plt.title(\"Top 10 Feature Importances (Gradient Boosting)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.059394Z",
     "iopub.status.busy": "2026-01-20T13:49:00.059394Z",
     "iopub.status.idle": "2026-01-20T13:49:00.070345Z",
     "shell.execute_reply": "2026-01-20T13:49:00.070345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Val_AUC</th>\n",
       "      <th>AUC_Gap</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Val_RMSE</th>\n",
       "      <th>RMSE_Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.856029</td>\n",
       "      <td>0.693914</td>\n",
       "      <td>0.162116</td>\n",
       "      <td>0.351933</td>\n",
       "      <td>0.379290</td>\n",
       "      <td>0.027356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.786562</td>\n",
       "      <td>0.693174</td>\n",
       "      <td>0.093389</td>\n",
       "      <td>0.357419</td>\n",
       "      <td>0.380680</td>\n",
       "      <td>0.023260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>0.374962</td>\n",
       "      <td>0.379806</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.379684</td>\n",
       "      <td>0.383817</td>\n",
       "      <td>0.004133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train_AUC   Val_AUC   AUC_Gap  Train_RMSE  Val_RMSE  \\\n",
       "0        Random Forest   0.856029  0.693914  0.162116    0.351933  0.379290   \n",
       "1    Gradient Boosting   0.786562  0.693174  0.093389    0.357419  0.380680   \n",
       "2  Logistic Regression   0.712319  0.690397  0.021921    0.374962  0.379806   \n",
       "3        Decision Tree   0.689931  0.667967  0.021965    0.379684  0.383817   \n",
       "\n",
       "   RMSE_Gap  \n",
       "0  0.027356  \n",
       "1  0.023260  \n",
       "2  0.004845  \n",
       "3  0.004133  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = results_df[\n",
    "    [\"Model\", \"Train_AUC\", \"Val_AUC\", \"AUC_Gap\", \"Train_RMSE\", \"Val_RMSE\", \"RMSE_Gap\"]\n",
    "].copy()\n",
    "\n",
    "comparison_df[[\"Train_AUC\", \"Val_AUC\", \"AUC_Gap\", \"Train_RMSE\", \"Val_RMSE\", \"RMSE_Gap\"]] = (\n",
    "    comparison_df[[\"Train_AUC\", \"Val_AUC\", \"AUC_Gap\", \"Train_RMSE\", \"Val_RMSE\", \"RMSE_Gap\"]].round(6)\n",
    ")\n",
    "\n",
    "comparison_df = comparison_df.sort_values(\"Val_AUC\", ascending=False).reset_index(drop=True)\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the highest validation AUC is selected as the leading candidate. The AUC_Gap column highlights overfitting risk: larger gaps indicate stronger train–validation divergence. RMSE values provide a probability calibration check; small RMSE_Gap values suggest stable generalization. Overall improvements are modest but consistent with credit‑risk modeling norms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the final model for business thresholding based on validation AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.072547Z",
     "iopub.status.busy": "2026-01-20T13:49:00.072547Z",
     "iopub.status.idle": "2026-01-20T13:49:00.076625Z",
     "shell.execute_reply": "2026-01-20T13:49:00.076625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Random Forest'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_MODEL_NAME = comparison_df.loc[0, \"Model\"]\n",
    "\n",
    "FINAL_PIPELINE = {\n",
    "    \"Logistic Regression\": log_reg_pipeline,\n",
    "    \"Decision Tree\": best_tree_pipeline,\n",
    "    \"Random Forest\": rf_best_pipeline,\n",
    "    \"Gradient Boosting\": gb_best_pipeline,\n",
    "}[FINAL_MODEL_NAME]\n",
    "\n",
    "FINAL_MODEL_NAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Optimization (Business)\n",
    "\n",
    "Positive class is `default = 1`, and the model outputs P(default). We make a lending decision by comparing the predicted default probability to a threshold: **approve** if P(default) < threshold, **reject** otherwise. The optimal threshold depends on business costs and benefits. Thresholds are chosen on the validation set; the test set is reserved for final evaluation only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Assumptions\n",
    "\n",
    "Because no monetary cost-benefit values are provided, we use a clear, outcome-based payoff matrix (defined in `PAYOFF`):\n",
    "\n",
    "- Approve & non‑default: +1\n",
    "- Approve & default: −5\n",
    "- Reject & default: 0\n",
    "- Reject & non‑default: −1\n",
    "\n",
    "Defaults are much more costly than missed opportunities, so the policy is intentionally conservative. These values are illustrative but economically reasonable for decision‑making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.079180Z",
     "iopub.status.busy": "2026-01-20T13:49:00.079180Z",
     "iopub.status.idle": "2026-01-20T13:49:00.376479Z",
     "shell.execute_reply": "2026-01-20T13:49:00.376479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline approvals: 2529, defaults among approved: 486, approval rate: 0.998\n",
      "Optimal approvals: 2076, defaults among approved: 303, approval rate: 0.820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multiplier</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>best_expected_value</th>\n",
       "      <th>best_approval_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-65.6</td>\n",
       "      <td>0.819582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.819582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.819582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   multiplier  best_threshold  best_expected_value  best_approval_rate\n",
       "0         0.8            0.29                -65.6            0.819582\n",
       "1         1.0            0.29                -14.0            0.819582\n",
       "2         1.2            0.29                 37.6            0.819582"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_proba = FINAL_PIPELINE.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "results_threshold = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    approve = val_proba < threshold\n",
    "\n",
    "    approve_nondefault = ((approve) & (y_val == 0)).sum()\n",
    "    approve_default = ((approve) & (y_val == 1)).sum()\n",
    "    reject_nondefault = ((~approve) & (y_val == 0)).sum()\n",
    "    reject_default = ((~approve) & (y_val == 1)).sum()\n",
    "\n",
    "    expected_value = (\n",
    "        approve_nondefault * PAYOFF[\"approve_nondefault\"]\n",
    "        + approve_default * PAYOFF[\"approve_default\"]\n",
    "        + reject_default * PAYOFF[\"reject_default\"]\n",
    "        + reject_nondefault * PAYOFF[\"reject_nondefault\"]\n",
    "    )\n",
    "\n",
    "    approval_rate = approve.mean()\n",
    "\n",
    "    results_threshold.append(\n",
    "        {\n",
    "            \"threshold\": threshold,\n",
    "            \"expected_value\": expected_value,\n",
    "            \"approval_rate\": approval_rate,\n",
    "            \"approve_nondefault\": approve_nondefault,\n",
    "            \"approve_default\": approve_default,\n",
    "            \"reject_nondefault\": reject_nondefault,\n",
    "            \"reject_default\": reject_default,\n",
    "        }\n",
    "    )\n",
    "\n",
    "threshold_df = pd.DataFrame(results_threshold)\n",
    "\n",
    "best_idx = threshold_df[\"expected_value\"].idxmax()\n",
    "best_threshold = threshold_df.loc[best_idx, \"threshold\"]\n",
    "best_expected_value = threshold_df.loc[best_idx, \"expected_value\"]\n",
    "best_approval_rate = threshold_df.loc[best_idx, \"approval_rate\"]\n",
    "\n",
    "# Expected value curve\n",
    "ev_fig, ev_ax = plt.subplots(figsize=(7, 4))\n",
    "ev_ax.plot(threshold_df[\"threshold\"], threshold_df[\"expected_value\"], marker=\"o\", markersize=3)\n",
    "ev_ax.axvline(best_threshold, color=\"red\", linestyle=\"--\", label=f\"Best threshold = {best_threshold:.2f}\")\n",
    "ev_ax.set_title(\"Expected Value vs Threshold (Validation)\")\n",
    "ev_ax.set_xlabel(\"Threshold\")\n",
    "ev_ax.set_ylabel(\"Expected Value\")\n",
    "ev_ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Approval rate curve\n",
    "approval_fig, approval_ax = plt.subplots(figsize=(7, 4))\n",
    "approval_ax.plot(threshold_df[\"threshold\"], threshold_df[\"approval_rate\"], marker=\"o\", markersize=3)\n",
    "approval_ax.axvline(best_threshold, color=\"red\", linestyle=\"--\", label=f\"Best threshold = {best_threshold:.2f}\")\n",
    "approval_ax.set_title(\"Approval Rate vs Threshold (Validation)\")\n",
    "approval_ax.set_xlabel(\"Threshold\")\n",
    "approval_ax.set_ylabel(\"Approval Rate\")\n",
    "approval_ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion-style tables at 0.50 and optimal threshold\n",
    "\n",
    "def decision_table(threshold):\n",
    "    approve = val_proba < threshold\n",
    "    approve_nondefault = int(((approve) & (y_val == 0)).sum())\n",
    "    approve_default = int(((approve) & (y_val == 1)).sum())\n",
    "    reject_nondefault = int(((~approve) & (y_val == 0)).sum())\n",
    "    reject_default = int(((~approve) & (y_val == 1)).sum())\n",
    "\n",
    "    table = pd.DataFrame(\n",
    "        {\n",
    "            \"Non-default\": [approve_nondefault, reject_nondefault],\n",
    "            \"Default\": [approve_default, reject_default],\n",
    "        },\n",
    "        index=[\"Approved\", \"Rejected\"],\n",
    "    )\n",
    "\n",
    "    approvals = approve.sum()\n",
    "    bad_approvals = approve_default\n",
    "    approval_rate = approvals / len(y_val)\n",
    "\n",
    "    return table, approvals, bad_approvals, approval_rate\n",
    "\n",
    "baseline_table, baseline_approvals, baseline_bad, baseline_rate = decision_table(0.50)\n",
    "optimal_table, optimal_approvals, optimal_bad, optimal_rate = decision_table(best_threshold)\n",
    "\n",
    "baseline_table, optimal_table\n",
    "print(f\"Baseline approvals: {baseline_approvals}, defaults among approved: {baseline_bad}, approval rate: {baseline_rate:.3f}\")\n",
    "print(f\"Optimal approvals: {optimal_approvals}, defaults among approved: {optimal_bad}, approval rate: {optimal_rate:.3f}\")\n",
    "\n",
    "# Sensitivity analysis: scale approve outcomes by ±20%\n",
    "\n",
    "sensitivity_rows = []\n",
    "for multiplier in [0.8, 1.0, 1.2]:\n",
    "    payoff = PAYOFF.copy()\n",
    "    payoff[\"approve_nondefault\"] = PAYOFF[\"approve_nondefault\"] * multiplier\n",
    "    payoff[\"approve_default\"] = PAYOFF[\"approve_default\"] * multiplier\n",
    "\n",
    "    values = []\n",
    "    approvals = []\n",
    "    for threshold in thresholds:\n",
    "        approve = val_proba < threshold\n",
    "        approve_nondefault = ((approve) & (y_val == 0)).sum()\n",
    "        approve_default = ((approve) & (y_val == 1)).sum()\n",
    "        reject_nondefault = ((~approve) & (y_val == 0)).sum()\n",
    "        reject_default = ((~approve) & (y_val == 1)).sum()\n",
    "\n",
    "        ev = (\n",
    "            approve_nondefault * payoff[\"approve_nondefault\"]\n",
    "            + approve_default * payoff[\"approve_default\"]\n",
    "            + reject_default * payoff[\"reject_default\"]\n",
    "            + reject_nondefault * payoff[\"reject_nondefault\"]\n",
    "        )\n",
    "\n",
    "        values.append(ev)\n",
    "        approvals.append(approve.mean())\n",
    "\n",
    "    best_idx = int(np.argmax(values))\n",
    "    sensitivity_rows.append(\n",
    "        {\n",
    "            \"multiplier\": multiplier,\n",
    "            \"best_threshold\": thresholds[best_idx],\n",
    "            \"best_expected_value\": values[best_idx],\n",
    "            \"best_approval_rate\": approvals[best_idx],\n",
    "        }\n",
    "    )\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_rows)\n",
    "\n",
    "sensitivity_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity results show how the optimal threshold shifts when approval payoffs are scaled by ±20%. A stable threshold indicates robust decisioning; larger shifts indicate stronger dependence on business cost assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.378588Z",
     "iopub.status.busy": "2026-01-20T13:49:00.378588Z",
     "iopub.status.idle": "2026-01-20T13:49:00.389197Z",
     "shell.execute_reply": "2026-01-20T13:49:00.389197Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(threshold_df[\"threshold\"], threshold_df[\"expected_value\"], marker=\"o\", markersize=3)\n",
    "plt.axvline(best_threshold, color=\"red\", linestyle=\"--\", label=f\"Best threshold = {best_threshold:.2f}\")\n",
    "plt.title(\"Expected Value vs Threshold (Validation)\")\n",
    "plt.xlabel(\"Classification Threshold\")\n",
    "plt.ylabel(\"Expected Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The optimal threshold from the validation expected-value curve (reported above) reflects a more conservative lending policy, because default costs are much larger than missed repayment opportunities. If default costs were lower or opportunity costs higher, the optimal threshold would shift downward to approve more loans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Takeaways\n",
    "\n",
    "Below we summarize model performance, the final model choice, and the threshold policy used for business decisioning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.391293Z",
     "iopub.status.busy": "2026-01-20T13:49:00.391293Z",
     "iopub.status.idle": "2026-01-20T13:49:00.397865Z",
     "shell.execute_reply": "2026-01-20T13:49:00.397865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_model</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>best_expected_value</th>\n",
       "      <th>best_approval_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-14</td>\n",
       "      <td>0.819582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     final_model  best_threshold  best_expected_value  best_approval_rate\n",
       "0  Random Forest            0.29                  -14            0.819582"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df\n",
    "\n",
    "threshold_summary = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"final_model\": FINAL_MODEL_NAME,\n",
    "            \"best_threshold\": best_threshold,\n",
    "            \"best_expected_value\": best_expected_value,\n",
    "            \"best_approval_rate\": best_approval_rate,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "threshold_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The final model is selected by highest validation AUC to maximize generalization performance.\n",
    "- The AUC_Gap column provides an overfitting check; smaller gaps indicate more stable models.\n",
    "- RMSE complements AUC by reflecting probability calibration quality.\n",
    "- The optimal threshold balances approval volume and default risk under the payoff assumptions.\n",
    "- Sensitivity analysis indicates how robust the threshold is to cost shifts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.401239Z",
     "iopub.status.busy": "2026-01-20T13:49:00.401239Z",
     "iopub.status.idle": "2026-01-20T13:49:00.405223Z",
     "shell.execute_reply": "2026-01-20T13:49:00.404365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_version: 3.12.6\n",
      "pandas_version: 2.2.2\n",
      "numpy_version: 2.1.1\n",
      "sklearn_version: 1.5.2\n",
      "random_state: 42\n",
      "train_shape: (7596, 27) val_shape: (2533, 27)\n",
      "target_mean_train: 0.19286466561348078 target_mean_val: 0.19265692854322938\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "\n",
    "print(\"python_version:\", sys.version.split()[0])\n",
    "print(\"pandas_version:\", pd.__version__)\n",
    "print(\"numpy_version:\", np.__version__)\n",
    "print(\"sklearn_version:\", sklearn.__version__)\n",
    "print(\"random_state:\", RANDOM_STATE)\n",
    "print(\"train_shape:\", X_train.shape, \"val_shape:\", X_val.shape)\n",
    "print(\"target_mean_train:\", y_train.mean(), \"target_mean_val:\", y_val.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test Evaluation\n",
    "\n",
    "Final test evaluation is intentionally deferred to preserve an unbiased hold‑out set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook follows the full supervised learning workflow for credit risk, with clear separation between exploration, modeling, and business decisioning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Artifacts (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:49:00.407299Z",
     "iopub.status.busy": "2026-01-20T13:49:00.407299Z",
     "iopub.status.idle": "2026-01-20T13:49:01.214037Z",
     "shell.execute_reply": "2026-01-20T13:49:01.214037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT_DIR: C:\\Users\\mail\\OneDrive\\Desktop\\credit-risk-ml-mif\\outputs\n",
      "approval_rate_curve_validation.png: 90.6 KB\n",
      "confusion_matrix_validation_050.csv: 0.1 KB\n",
      "confusion_matrix_validation_optimal.csv: 0.1 KB\n",
      "ev_curve_validation.png: 103.4 KB\n",
      "feature_importance_final_model.csv: 3.3 KB\n",
      "feature_importance_final_model.png: 108.3 KB\n",
      "model_card.md: 2.4 KB\n",
      "model_comparison_validation.csv: 0.3 KB\n",
      "outputs_manifest.txt: 2.0 KB\n",
      "threshold_sensitivity.csv: 0.2 KB\n",
      "threshold_sweep_validation.csv: 4.0 KB\n",
      "tuning_decision_tree.csv: 0.7 KB\n",
      "tuning_gradient_boosting.csv: 0.4 KB\n",
      "tuning_random_forest.csv: 1.5 KB\n",
      "EXPORT COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import hashlib\n",
    "\n",
    "FINAL_OUTPUT_FILES = [\n",
    "    \"model_card.md\",\n",
    "    \"model_comparison_validation.csv\",\n",
    "    \"tuning_decision_tree.csv\",\n",
    "    \"tuning_random_forest.csv\",\n",
    "    \"tuning_gradient_boosting.csv\",\n",
    "    \"feature_importance_final_model.csv\",\n",
    "    \"feature_importance_final_model.png\",\n",
    "    \"ev_curve_validation.png\",\n",
    "    \"approval_rate_curve_validation.png\",\n",
    "    \"confusion_matrix_validation_050.csv\",\n",
    "    \"confusion_matrix_validation_optimal.csv\",\n",
    "    \"threshold_sweep_validation.csv\",\n",
    "    \"threshold_sensitivity.csv\",\n",
    "]\n",
    "MANIFEST_NAME = \"outputs_manifest.txt\"\n",
    "\n",
    "OPTIONAL_APPENDIX_FILES = []\n",
    "\n",
    "# Cleanup: remove existing known outputs only (clean export)\n",
    "for name in FINAL_OUTPUT_FILES + [MANIFEST_NAME]:\n",
    "    p = OUTPUT_DIR / name\n",
    "    if p.exists():\n",
    "        p.unlink()\n",
    "\n",
    "# Export tables\n",
    "comparison_df.to_csv(OUTPUT_DIR / \"model_comparison_validation.csv\", index=False)\n",
    "\n",
    "dt_tuning_df.to_csv(OUTPUT_DIR / \"tuning_decision_tree.csv\", index=False)\n",
    "rf_tuning_df.to_csv(OUTPUT_DIR / \"tuning_random_forest.csv\", index=False)\n",
    "gb_tuning_df.to_csv(OUTPUT_DIR / \"tuning_gradient_boosting.csv\", index=False)\n",
    "\n",
    "threshold_df.to_csv(OUTPUT_DIR / \"threshold_sweep_validation.csv\", index=False)\n",
    "sensitivity_df.to_csv(OUTPUT_DIR / \"threshold_sensitivity.csv\", index=False)\n",
    "\n",
    "baseline_table.to_csv(OUTPUT_DIR / \"confusion_matrix_validation_050.csv\")\n",
    "optimal_table.to_csv(OUTPUT_DIR / \"confusion_matrix_validation_optimal.csv\")\n",
    "\n",
    "# Export curves\n",
    "if \"ev_fig\" in globals():\n",
    "    ev_fig.savefig(OUTPUT_DIR / \"ev_curve_validation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "if \"approval_fig\" in globals():\n",
    "    approval_fig.savefig(OUTPUT_DIR / \"approval_rate_curve_validation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Feature importance for final model (no retraining)\n",
    "feature_names = FINAL_PIPELINE.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "model = FINAL_PIPELINE.named_steps[\"model\"]\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    importances = model.feature_importances_\n",
    "elif hasattr(model, \"coef_\"):\n",
    "    importances = np.abs(model.coef_).ravel()\n",
    "else:\n",
    "    importances = None\n",
    "\n",
    "if importances is None:\n",
    "    raise RuntimeError(\"Final model does not expose feature importances.\")\n",
    "\n",
    "fi_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "fi_df = fi_df.sort_values(\"importance\", ascending=False)\n",
    "fi_df.to_csv(OUTPUT_DIR / \"feature_importance_final_model.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    data=fi_df.head(10),\n",
    "    orient=\"h\",\n",
    ")\n",
    "plt.title(f\"Top 10 Feature Importances ({FINAL_MODEL_NAME})\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.savefig(OUTPUT_DIR / \"feature_importance_final_model.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Model card\n",
    "final_row = comparison_df.loc[comparison_df[\"Model\"] == FINAL_MODEL_NAME].iloc[0]\n",
    "model_card = f\"\"\"# Model Card\n",
    "\n",
    "## Executive Summary\n",
    "- Predicts probability of default to support lending decisions.\n",
    "- Final model selected by highest validation AUC for generalization.\n",
    "- Threshold policy balances approval volume and default risk.\n",
    "- Decisioning is grounded in transparent payoff assumptions.\n",
    "\n",
    "## Data & Split\n",
    "- Train rows: {X_train.shape[0]}\n",
    "- Validation rows: {X_val.shape[0]}\n",
    "- Test rows: {df_test.shape[0]}\n",
    "- Target prevalence (train): {y_train.mean():.4f}\n",
    "- Target prevalence (validation): {y_val.mean():.4f}\n",
    "- Random state: {RANDOM_STATE}\n",
    "\n",
    "## Feature Engineering\n",
    "- Affordability: installment_to_income, loan_to_income\n",
    "- Leverage: revol_balance_util, revol_balance_to_income\n",
    "- Stability/experience: open_to_total_acc, recent_inquiry_flag\n",
    "- Nonlinear: log_annual_inc, sqrt_dti\n",
    "\n",
    "## Models Compared\n",
    "Model performance is summarized in `model_comparison_validation.csv`. The final model is selected based on validation AUC, with AUC gap used to monitor overfitting risk.\n",
    "\n",
    "## Final Policy (Validation)\n",
    "- Final model: {FINAL_MODEL_NAME}\n",
    "- Validation AUC: {final_row['Val_AUC']:.4f}\n",
    "- Validation RMSE: {final_row['Val_RMSE']:.4f}\n",
    "- Optimal threshold: {best_threshold:.2f}\n",
    "- Approval rate: {best_approval_rate:.3f}\n",
    "- Expected value: {best_expected_value}\n",
    "\n",
    "## Confusion Matrices (Validation)\n",
    "- Threshold 0.50: approvals={baseline_approvals}, defaults among approved={baseline_bad}, approval_rate={baseline_rate:.3f}\n",
    "- Optimal threshold: approvals={optimal_approvals}, defaults among approved={optimal_bad}, approval_rate={optimal_rate:.3f}\n",
    "- Full tables are saved in `confusion_matrix_validation_050.csv` and `confusion_matrix_validation_optimal.csv`.\n",
    "\n",
    "## Assumptions & Interpretation\n",
    "The decision policy is based on stylized payoff assumptions (e.g., -5 for a default and +1 for a successful repayment). Under these assumptions, the optimal threshold is chosen to minimize expected loss (or maximize expected value). It is important to note that the resulting Expected Value (EV) may be negative if the baseline default rate is high or if the model’s discriminative power is limited. The sensitivity analysis (`threshold_sensitivity.csv`) further explores how the optimal threshold and corresponding EV shift under different cost-benefit calibrations, highlighting the dependence of the policy on these business assumptions.\n",
    "\n",
    "## Limitations & Next Steps\n",
    "- Payoff assumptions are stylized; calibrate to bank economics.\n",
    "- Threshold chosen on validation; test remains untouched for final audit.\n",
    "- Monitor drift and recalibrate thresholds as conditions change.\n",
    "- Consider calibration and fairness analyses as follow-on work.\n",
    "\n",
    "## Reproducibility\n",
    "- Run `notebooks/credit_risk_project.ipynb` → Restart Kernel & Run All.\n",
    "\"\"\"\n",
    "(OUTPUT_DIR / \"model_card.md\").write_text(model_card, encoding=\"utf-8\")\n",
    "\n",
    "# Outputs manifest (Deterministic: no timestamps, sorted files, git hash or unknown)\n",
    "try:\n",
    "    commit_hash = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], text=True).strip()\n",
    "except Exception:\n",
    "    commit_hash = \"unknown\"\n",
    "\n",
    "purposes = {\n",
    "    \"model_card.md\": \"Executive summary of model, metrics, and policy.\",\n",
    "    \"model_comparison_validation.csv\": \"Validation metrics for all models.\",\n",
    "    \"tuning_decision_tree.csv\": \"Decision Tree tuning grid results.\",\n",
    "    \"tuning_random_forest.csv\": \"Random Forest tuning grid results.\",\n",
    "    \"tuning_gradient_boosting.csv\": \"Gradient Boosting tuning grid results.\",\n",
    "    \"feature_importance_final_model.csv\": \"Feature importances for final model.\",\n",
    "    \"feature_importance_final_model.png\": \"Top-10 feature importance chart.\",\n",
    "    \"ev_curve_validation.png\": \"Expected value vs threshold curve.\",\n",
    "    \"approval_rate_curve_validation.png\": \"Approval rate vs threshold curve.\",\n",
    "    \"confusion_matrix_validation_050.csv\": \"Confusion table at threshold=0.50.\",\n",
    "    \"confusion_matrix_validation_optimal.csv\": \"Confusion table at optimal threshold.\",\n",
    "    \"threshold_sweep_validation.csv\": \"Threshold sweep metrics on validation.\",\n",
    "    \"threshold_sensitivity.csv\": \"Sensitivity of optimal threshold to payoff shifts.\",\n",
    "}\n",
    "\n",
    "manifest_lines = [\n",
    "    f\"git_commit: {commit_hash}\",\n",
    "    \"files:\",\n",
    "]\n",
    "\n",
    "for name in sorted(FINAL_OUTPUT_FILES):\n",
    "    path = OUTPUT_DIR / name\n",
    "    if not path.exists():\n",
    "        continue\n",
    "    size_kb = path.stat().st_size / 1024\n",
    "    with open(path, \"rb\") as f:\n",
    "        sha256 = hashlib.sha256(f.read()).hexdigest()\n",
    "    manifest_lines.append(f\"- {name} | {size_kb:.1f} KB | {sha256} | {purposes.get(name, '')}\")\n",
    "\n",
    "(OUTPUT_DIR / MANIFEST_NAME).write_text(\"\\n\".join(manifest_lines), encoding=\"utf-8\")\n",
    "# Verification printout\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR.resolve()}\")\n",
    "exported_files = sorted([p for p in OUTPUT_DIR.iterdir() if p.is_file()])\n",
    "for path in exported_files:\n",
    "    size_kb = path.stat().st_size / 1024\n",
    "    print(f\"{path.name}: {size_kb:.1f} KB\")\n",
    "print(\"EXPORT COMPLETE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
